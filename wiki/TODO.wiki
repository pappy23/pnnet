#summary Че надо делать в первую очередь?
  * ~~Несимметричные или параллельные линки. Они никак не отлавливаются.~~
{{{
Net::addConnection() нормально работает, но пользователю доступны ф-ии нейрона напрямую,
т.е. он может соединить их вообще как душе угодно. Это не есть хорошо.
Update:
Перенесено в Issues
}}}

  * Проверить качество алгоритма обучения, его соответствие теории, особенно с общими линками.

  * ~~Описание в отдельном доке(статьи)~~
{{{
Возможные проблемы и варианты их решения будут или сдесь, или в коде с пометкой TODO.
Сложно держать внешнюю документацию в актуальном состоянии.
}}}

  * ~~Написать парсер PPM/PGM/PBM, убрать зависимости от boost::gil/libjpeg~~
{{{
Серегин экспериментальный, стремный, но работающий парсер влился в код. Ура, товарищи!
Осталось выкинуть libjpeg и подогнать под это дело существующие программы
}}}

  * ~~Doxygen~~
{{{
Взял на вооружение. Дело даже не в доксиджене, а вообще в каментах.
Надо их оставлять
}}}

  * ~~Модель сверточной сети. Неплохо бы ее как-то формализовать, выделить подпрограммы и т.п. Потому что то что есть - выглядит ужасно.~~
{{{
Сказано - сделано. Более-менее формализовано и влито в NetworkModels
}}}

  * ~~Починить сериализацию так, что бы она не хавала столько стека. Пока что решение - юзать ulimit -s~~
{{{
`Код сериализации сейчас очень красивый. Все замечательно, кроме того,`
`что он сильно рекуррентный. Нужно придумать красивое решение проблемы.`
`Пока что предлагаю, пока красивого решения нет, не пороть горячку и ничего не трогать.`
`Будем довольствоваться увеличением стека.`

Update 29.05.2009:
Сделал tag того что было. После этого поправил сериализацию. Суть поправки такова:
Шаг первый. Если мы сохраняем сеть, то обновить кеш.
Шаг второй. Сериализировать кеш, который в свою очередь сериализирует нейроны.
Нейроны не сериализируют собственные соединения. Т. о. - пока что никакой рекурсии.
Шаг третий: Пройтись по всем вручную и сериализировать их соединения.
На момент сериализации соединений все нейроны уже записаны в файл,
т.е. нет никакой рекурсии.
Минусы:
Код стал кривоват. К примеру BOOST_SERIALIZATION_NVP не работает на 
cache.layers[i][j]->links_out()  (не может определить имя для сериализации и вываливается с archive_exception::no_exception =) ).
Пришлось делать руками: ar & make_nvp("links_out", cache.layers[i][j]->links_out)
А еще пришлось объявить Net другом класса Neuron.
Плюсы:
Убрали рекурсию. Ибо сериализация в boost даже без рекурсии обходится в глубину вызовов порядка 20-30. А то что было раньше - глубина вызовов пару десятков тысяч - 
это ж смертный грех и тихий ужас.
}}}

  * ~~После рефакторинга ядра нужно проверить все. Написать Unit-тесты и пр. Все ли деструкторы вызываются, нет ли зависших нейронов/линков, нет ли неоднозначностей с рекуррентными топологиями?~~
{{{
Проверил. Все деструкторы вовремя вызываются.
В принципе то что касается Core, полностью покрыто тестом TestNet. 
Все остальное вроде как тоже неплохо покрывается с помощью других тестов. 
Не думаю что целесообразно писать унылые юнит-тесты, что бы тестить класс с двумя методами.
Прогнал тестовые программы через valgrind - никаких проблем. 
Обнаружены только проблемы с производительностью. Но это уже совсем другая история.
Рекуррентные топологии поддерживаются в полном объеме.
Ограничения топологии:
 - можно напутать с latency и тогда топология может неправильно строить кеш. В таких нештатных ситуациях алгоритм не тестировался.
 - если удалить нейрон, то указатель на него остается в кеше, так что реально нейрон удаляется только при перестройке кеша.
Это не проблема, просто надо об этом помнить
 - если удалить нейроны так, что кусок топологии останется отрезан от входных нейронов,
то этот кусок останется висеть в памяти до завершения программы, потому как оставшиеся
нейроны будут продолжать ссылаться друг на друга. 
Не думаю что это такая уж большая проблема и ее нужно кидаться фиксить. 
Просто надо об этом помнить. 
weak_ptr внутри Link не предлагать.
}}}

 * ~~oprofile, valgrind - отловить тормоза и пр.~~
{{{
valgrind опробован. Лед тронулся. Будем юзать. Когда понадобиться что-то оптимизировать.
}}}
  
  * ~~Всякая всячина, помеченная в коде как TODO, FIXME~~
{{{
Лед тронулся. Будем юзать. Периодически буду делать `grep TODO *`
}}}

  * ~~Автоматическое тестирование~~
{{{
Можно заюзать boost unit test library. Довольно прикольная штука.
CTest для юнит-тестирования + CDash для анализа
Все это хорошо, но этим никто не будет пользоваться. 80% времени уйдет на написание юнит-тестов, которые никому не нужны. Значит и писать их никто не будет.
Так что пока что оставляем высокоуровневое ручное тестирование. 
А CTest и boost testing оставим до лучших времен.
PS: man gcc, -fprogile-arcs, -ftest-coverage; man gcov
}}}

  * ~~Ограничения волнового алгоритма. См. каменты в коде~~
{{{
Поменял алгоритм. Проверил на Хопфилд-подобной архитектуре(см. TestNet.cpp).
С виду - никаких проблем. Поживем, увидим, как оно.
}}}

  * ~~Проблемы с addConnection/delConnection. См. TODO коде~~
{{{
Да, выглядит не очень эстетично, но работает. Больше волнует проблема с возможными параллельными или несимметричными линками.
}}}